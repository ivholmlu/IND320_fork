{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark\n",
    "- A fast and general compute engine (for [Hadoop](https://hadoop.apache.org/) data).\n",
    "    - Often paired with Hadoop for its distributed filesystem (HDFS), cluster resource management and parallel processing.\n",
    "- Spark provides a simple and expressive programming model that supports a wide range of applications, including ETL (extract, transform, load), Machine Learning, stream processing, and graph computation.\n",
    "- Also communicates well with some databases and other resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark and Cassandra\n",
    "- Cassandra is one of the databases that work well with Spark.\n",
    "    - Same type of distributed processing.\n",
    "    - Same way of replicating for fault tolerance.\n",
    "- Spark can be deployed on the same nodes as Cassandra for:\n",
    "    - local (short traveled) data manipulation, and\n",
    "    - combination of results to a central hub ([MapReduce](https://en.wikipedia.org/wiki/MapReduce)).\n",
    "- Requires drivers from Datastax\n",
    "    - Automatically downloaded and applied with the following configuration.\n",
    "- A [SparkSession](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html) instantiates Spark, applies configurations and connects to a data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkCassandraApp').\\\n",
    "    config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.4.1').\\\n",
    "    config('spark.cassandra.connection.host', 'localhost').\\\n",
    "    config('spark.sql.extensions', 'com.datastax.spark.connector.CassandraSparkExtensions').\\\n",
    "    config('spark.sql.catalog.mycatalog', 'com.datastax.spark.connector.datasource.CassandraCatalog').\\\n",
    "    config('spark.cassandra.connection.port', '9042').getOrCreate()\n",
    "# Some warnings are to be expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+\n",
      "|ind| company|  model|\n",
      "+---+--------+-------+\n",
      "|  3|Polestar|      3|\n",
      "|  1|   Tesla|Model S|\n",
      "|  2|   Tesla|Model 3|\n",
      "+---+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# .load() is used to load data from Cassandra table as a Spark DataFrame.\n",
    "spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"my_first_table\", keyspace=\"my_first_keyspace\").load().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database views\n",
    "- Useful for \"setting the scene\" before a more simplified data extraction.\n",
    "- The below example simply attaches to the correct keyspace and table.\n",
    "    - The _view_ could also be a selection into that table to query further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create view for simpler SQL queries\n",
    "spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"table_with_uuid\", keyspace=\"my_first_keyspace\").load().createOrReplaceTempView(\"my_first_table_view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Spark DataFrame](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html)\n",
    "- Related to a Pandas data frame, but can be distributed over compute nodes.\n",
    "- Various functions like filters, statistical calculations, groupBy, Pandas functions (mapInPandas), joins, etc.\n",
    "- Export to Pandas and JSON.\n",
    "- Reads many formats, including SQL, JSON, Excel, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "| planet| distance|\n",
      "+-------+---------+\n",
      "|Mercury| 0.387 AU|\n",
      "|  Venus| 0.723 AU|\n",
      "|  Earth| 1.000 AU|\n",
      "|   Mars| 1.524 AU|\n",
      "|Jupiter| 5.203 AU|\n",
      "| Saturn| 9.546 AU|\n",
      "| Uranus|19.218 AU|\n",
      "|Neptune|30.069 AU|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read CSV file into Spark DataFrame\n",
    "planets = spark.read.csv(\"../../data/planets.csv\", header=True, inferSchema=True)\n",
    "planets.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-------+-------+\n",
      "|                  id|company|  model|  price|\n",
      "+--------------------+-------+-------+-------+\n",
      "|d99d3340-4b02-11e...|  Tesla|Model S|21000.0|\n",
      "|d99bd3b0-4b02-11e...|  Tesla|Model S|20000.0|\n",
      "+--------------------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select only Tesla company\n",
    "#             DataFrame                    -->\n",
    "spark.sql(\"select * from my_first_table_view\").filter(\"company = 'Tesla'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-------+-------+\n",
      "|                  id|company|  model|  price|\n",
      "+--------------------+-------+-------+-------+\n",
      "|d99bd3b0-4b02-11e...|  Tesla|Model S|20000.0|\n",
      "|d99d3340-4b02-11e...|  Tesla|Model S|21000.0|\n",
      "+--------------------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Equivalent to the above but in pure SQL\n",
    "spark.sql(\"select * from my_first_table_view where company = 'Tesla'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>model</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d99d3340-4b02-11ee-8fb7-47776a2dd8a7</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Model S</td>\n",
       "      <td>21000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d99da870-4b02-11ee-8fb7-47776a2dd8a7</td>\n",
       "      <td>Oldsmobile</td>\n",
       "      <td>Model 6C</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d99bd3b0-4b02-11ee-8fb7-47776a2dd8a7</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Model S</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id     company     model     price\n",
       "0  d99d3340-4b02-11ee-8fb7-47776a2dd8a7       Tesla   Model S   21000.0\n",
       "1  d99da870-4b02-11ee-8fb7-47776a2dd8a7  Oldsmobile  Model 6C  135000.0\n",
       "2  d99bd3b0-4b02-11ee-8fb7-47776a2dd8a7       Tesla   Model S   20000.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all data from the view and convert it to Pandas DataFrame\n",
    "spark.sql(\"select * from my_first_table_view\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>model</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d99bd3b0-4b02-11ee-8fb7-47776a2dd8a7</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Model S</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d99d3340-4b02-11ee-8fb7-47776a2dd8a7</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Model S</td>\n",
       "      <td>21000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id company    model    price\n",
       "0  d99bd3b0-4b02-11ee-8fb7-47776a2dd8a7   Tesla  Model S  20000.0\n",
       "1  d99d3340-4b02-11ee-8fb7-47776a2dd8a7   Tesla  Model S  21000.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View data as a table and select only Tesla company\n",
    "df = spark.sql(\"select * from my_first_table_view\")\n",
    "df.filter(df.company == 'Tesla').toPandas() # Equivalent to \"company = 'Tesla'\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>model</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d99d3340-4b02-11ee-8fb7-47776a2dd8a7</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Model S</td>\n",
       "      <td>21000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id company    model    price\n",
       "0  d99d3340-4b02-11ee-8fb7-47776a2dd8a7   Tesla  Model S  21000.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter also on price > 20000\n",
    "df.filter((df.company == 'Tesla') & (df.price > 20000)).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation, grouping and filtering\n",
    "- These can be combined in many ways.\n",
    "- Starting from the left.\n",
    "- Order is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>avg(price)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oldsmobile</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>20500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      company  avg(price)\n",
       "0  Oldsmobile    135000.0\n",
       "1       Tesla     20500.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate prices by company and sort by company name\n",
    "df.groupBy(\"company\").agg({\"price\": \"avg\"}).orderBy('company').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data to Cassandra\n",
    "- One can append or overwrite data in existing database tables.\n",
    "- PySpark is picky regarding data formats.\n",
    "    - Reading data from the existing table and extracting formatting is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>company</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>459</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Escort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>460</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Transit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ind company    model\n",
       "0  459    Ford   Escort\n",
       "1  460    Ford  Transit"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two new cars in a Pandas DataFrame\n",
    "import pandas as pd\n",
    "newCars = pd.DataFrame([[459, 'Ford', 'Escort'], [460, 'Ford', 'Transit']], columns=['ind', 'company', 'model'])\n",
    "newCars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Pandas DataFrame to Spark DataFrame and save it to Cassandra (append mode)\n",
    "spark.createDataFrame(newCars).write.format(\"org.apache.spark.sql.cassandra\").options(table=\"my_first_table\", keyspace=\"my_first_keyspace\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>company</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Polestar</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>460</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>459</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Escort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Model S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Model 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ind   company    model\n",
       "0    3  Polestar        3\n",
       "1  460      Ford  Transit\n",
       "2  459      Ford   Escort\n",
       "3    1     Tesla  Model S\n",
       "4    2     Tesla  Model 3"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the new cars are in the table\n",
    "spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"my_first_table\", keyspace=\"my_first_keyspace\").load().createOrReplaceTempView(\"my_first_table_view2\")\n",
    "spark.sql(\"select * from my_first_table_view2\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "try:\n",
    "    spark.stop()\n",
    "except ConnectionRefusedError:\n",
    "    print(\"Spark session already stopped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- [PySpark Tutorial For Beginners (sparkbyexample.com)](https://sparkbyexamples.com/pyspark-tutorial/)\n",
    "- [PySpark documentation](https://spark.apache.org/docs/latest/api/python/index.html)\n",
    "    - [PySpark DataFrame](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html)\n",
    "    - [PySpark SparkSession](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html)\n",
    "- [YouTube: PySpark Tutorial: Spark SQL & DataFrame Basics](https://youtu.be/3-pnWVWyH-s?si=5AfOao23gqgh19en) (17m:12s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_M1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
