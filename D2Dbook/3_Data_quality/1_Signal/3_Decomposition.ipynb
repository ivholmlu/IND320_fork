{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Decompostion\n",
    "- There are various regimes for signal decomposition.\n",
    "- Examples:\n",
    "    - Fast Fourier Transform (FFT)\n",
    "    - Wavelets\n",
    "    - Linear components\n",
    "- Motviation:\n",
    "    - Trend discovery\n",
    "    - Low-pass filter\n",
    "    - Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fast Fourier Transform\n",
    "### FFT history and application\n",
    "- An important workhorse in signal processing.\n",
    "- Can be traced back to Carl Friedrich Gauss on Discrete Fourier Transforms from 1805.\n",
    "- Major milestone in 1965 by James Cooley and John Tukey regarding speed of computations and applications in detecting Soviet nuclear bomb tests.\n",
    "- Used in anything from mathematical speed-ups, via video and music compression, modern signal processing in Wi-Fi, 5G, etc. to finance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### FFT function\n",
    "- Wikipedia: A Fourier Transform is a transform that converts a function into a form that describes the frequencies present in the original function.\n",
    "- scipy.fft: Fourier analysis is a method for expressing a function as a sum of peridoic components, and for recovering the signal from those components.\n",
    "  \n",
    "$$X_k = \\sum_{n=0}^{N-1} x_n e^{i2 \\pi kn/N} ~~~~ k = 0, ..., N-1$$\n",
    "- Here, _k_ is the index of a signal and _N_ is its length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Direct Cosine Transform (DCT)\n",
    "- FFT with real valued data.\n",
    "- For real numbered signals, the definition above can be exchanged with a version based on the cosine or sine functions.\n",
    "- There are theoretically 8+8 \"types\", 4+4 of which are implemented in SciPy, and various choices for normalisation.\n",
    "- Type I DCT (Direct Cosine Transform) as implemented in SciPy:\n",
    "$$y_k = x_0 + (-1)^k x_{N-1} + 2 \\sum_{n=1}^{N-2} x_n cos (\\frac{\\pi k n}{N-1}))$$\n",
    " - Quicker than FFT and guarantees real valued frequency domain.\n",
    " - Positive signal follow the base cosine waves, while negative signals indicate a horizontal shift of the cosine wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Sum of two cosines with different frequencies.\n",
    "import numpy as np\n",
    "from scipy.fft import dct, idct\n",
    "\n",
    "N = 601\n",
    "s = 6\n",
    "time   = np.linspace(0,s,N)\n",
    "signal = np.cos(3 * np.pi * time) + np.cos(5 * np.pi * time)\n",
    "\n",
    "# Plot the signal\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7,2))\n",
    "plt.plot(time, signal)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Signal')\n",
    "plt.xlim(0,s)\n",
    "plt.show()\n",
    "\n",
    "# Print the resolution of the time axis in Hz\n",
    "dt = time[1] - time[0]\n",
    "print('Sampling of the time axis:', 1/dt, 'Hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Discrete Cosine transform\n",
    "fourier_signal = dct(np.concatenate([np.zeros(0),signal])) # Pad with zeros to shift signal\n",
    "dt = time[1] - time[0]\n",
    "W = np.linspace(0, 1/dt, N)\n",
    "#                   ^-- Frequency axis in Hz\n",
    "\n",
    "# Plot the Fourier transform\n",
    "plt.figure(figsize=(7,2))\n",
    "plt.plot(W, fourier_signal)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Fourier Transform')\n",
    "#plt.xlim(0,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### FFT filtering\n",
    "- We can apply the FFT to analyse the frequencies present or to filter the signal.\n",
    "    - Filtering here means that some frequencies are removed from the signal.\n",
    "- Typical filters are:\n",
    "    - Low-pass filter: Remove high frequencies, e.g., noise or short-term changes, focusing on trends or slowly changing signals.\n",
    "    - High-pass filter: Remove low frequencies, e.g., trends or baselines, focusing on rapid changes or anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Remove frequencies below 4, i.e., a high-pass filter\n",
    "filtered_fourier_signal = fourier_signal.copy()\n",
    "filtered_fourier_signal[(W<4)] = 0 # <- Come playe with me!\n",
    "cut_signal = idct(filtered_fourier_signal)\n",
    "\n",
    "# Plot the filtered signal\n",
    "plt.figure(figsize=(7,2))\n",
    "plt.plot(time, cut_signal)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Filtered Signal')\n",
    "plt.xlim(0,6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# A curve we have seen before\n",
    "N = 301\n",
    "rng = np.random.default_rng(0)\n",
    "y = rng.standard_normal(N).cumsum()\n",
    "\n",
    "# Plot the curve\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(y)\n",
    "plt.xlabel('arbitrary units')\n",
    "plt.ylabel('amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the Fourier transform\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(np.abs(dct(y))) # Not caring about the phase\n",
    "plt.xlabel('frequency')  # Think 1/width of time series\n",
    "plt.ylabel('amplitude')\n",
    "plt.xlim(0,N)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Remove frequencies above 50, i.e., a low-pass filter.\n",
    "W = np.arange(0, N) # Frequency axis\n",
    "filtered_fourier_signal = dct(y).copy()\n",
    "filtered_fourier_signal[(W>50)] = 0\n",
    "cut_signal = idct(filtered_fourier_signal)\n",
    "\n",
    "# Plot the filtered signal\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(cut_signal)\n",
    "plt.xlabel('arbitrary units')\n",
    "plt.ylabel('amplitude')\n",
    "plt.xlim(0,N)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear decomposition\n",
    "- Various forms of linear models can be used for decomposition, each having different focus or optimality criteria, e.g.:\n",
    "    - Season-Trend decomposition using LOESS in the [statmodels package](https://www.statsmodels.org/stable/examples/notebooks/generated/stl_decomposition.html)\n",
    "    - Multivariate explorative data analysis with [Principal Coponent Analysis](https://hoggorm.readthedocs.io/en/latest/pca.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Seasonal-Trend decomposition using LOESS (STL)\n",
    "- STL takes a (time) series as input together with an estimate of period length.\n",
    "- Output are:\n",
    "    - A trend along the series.\n",
    "    - A seasonal signal which may evolve along the series.\n",
    "    - A residual.\n",
    "- Additional parameters:\n",
    "    - Length of smoothers for trend and season (high number = less change).\n",
    "    - Use weighting of samples for robustness (allow more individual deviation from trend/season)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Monthly sunspots from https://github.com/jbrownlee/Datasets\n",
    "\n",
    "# Load the data\n",
    "import pandas as pd\n",
    "sunspots = pd.read_csv(\"../../data/monthly-sunspots.csv\", header=0)\n",
    "print(sunspots.shape)\n",
    "sunspots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "sunspots.plot.line(x='Month', y='Sunspots', figsize=(7,2))\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of sunspots')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Approximate periodicity: Lenght of series divided by number of periods.\n",
    "# For sunspots we know that there is a periodicity of approximately 11 years.\n",
    "np.round(2820/21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import STL\n",
    "stl = STL(sunspots[\"Sunspots\"], period=134)#, robust=True, seasonal=1001, trend=1001)\n",
    "res = stl.fit() # Contains the components and a plot function\n",
    "fig = res.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Daily Female Births in California from https://github.com/jbrownlee/Datasets\n",
    "\n",
    "# Load the data\n",
    "births = pd.read_csv(\"../../data/daily-total-female-births.csv\", header=0)\n",
    "births.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stl = STL(births[\"Births\"], period=28)\n",
    "res = stl.fit()\n",
    "fig = res.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Excercise\n",
    "- Force the period to change less.\n",
    "- Extract the trend and plot it as a function of time.\n",
    "- Indicate the date of maximum number of conceptions (~9 months before birth), assuming the year is cyclic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiple seasonalities\n",
    "- If a there is more than one phenomenon with a cyclic behaviour, multiple seasonalities can be found through Multiple Seasonal-Trend decomposition using LOESS (MSTL).\n",
    "- The more complex model one applies, the higher the chances of overfitting!\n",
    "- [Example at statmodels.org](https://www.statmodels.org/dev/examples/notebooks/generated/mstl_decomposition.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Principal Component Analysis (PCA)\n",
    "- For (time) series with multiple variables, PCA can give a first indication of structure and connection between variables.\n",
    "- Scores show paths of time points, loadings show how variables relate.\n",
    "- One PCA formulation for input data $\\mathbf{X}$ with series as columns:\n",
    "$$\\mathbf{U} \\mathbf{S} \\mathbf{V}' = svd(\\mathbf{X}-\\bar{\\mathbf{X}})$$\n",
    "$$\\mathbf{T} = \\mathbf{U} \\mathbf{S} \\text{ - scores}$$\n",
    "$$\\mathbf{P} = \\mathbf{V}' \\text{ - loadings}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Beijing pollution data\n",
    "This dataset is originally from [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/381/beijing+pm2+5+data) and shows hourly measurements of weather at the US embassy in Bejing. Its columns are:\n",
    "1. No: row number\n",
    "2. year: year of data in this row\n",
    "3. month: month of data in this row\n",
    "4. day: day of data in this row\n",
    "5. hour: hour of data in this row\n",
    "6. pm2.5: PM2.5 concentration ($\\mu g/m^3$)\n",
    "7. DEWP: Dew Point ($^{\\circ}F$)\n",
    "8. TEMP: Temperature ($^{\\circ}F$)\n",
    "9. PRES: Pressure (_hPa_)\n",
    "10. cbwd: Combined wind direction\n",
    "11. Iws: Cumulated wind speed\n",
    "12. Is: Cumulated hours of snow\n",
    "13. Ir: Cumulated hours of rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Beijing pollution data from https://github.com/jbrownlee/Datasets\n",
    "\n",
    "# Load the data\n",
    "pollution = pd.read_csv(\"../../data/pollution.csv\", header=0, index_col=0)\n",
    "print(pollution.shape)\n",
    "pollution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Recode the cbwd column using one-hot encoding and add to the data frame\n",
    "pollution = pd.concat([pollution, pd.get_dummies(pollution[\"cbwd\"])], axis=1)\n",
    "pollution = pollution.drop(columns=[\"cbwd\"])\n",
    "pollution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Replace NaN with 0 in the pm2.5 column\n",
    "pollution[\"pm2.5\"] = pollution[\"pm2.5\"].fillna(0)\n",
    "pollution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# PCA of pollution data\n",
    "from hoggorm.pca import nipalsPCA as PCA\n",
    "pca = PCA(pollution.iloc[:,4:].values, numComp=4, Xstand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Make a 2D histogram of the X_scores (too many points for a scatter plot)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.hist2d(pca.X_scores()[:,0], pca.X_scores()[:,1], bins=200)\n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Loading plot\n",
    "from hoggormplot import loadings\n",
    "loadings(pca, comp=[1,2], XvarNames=pollution.columns[4:].tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Make a 2D histogram of the X_scores (too many points for a scatter plot)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.hist2d(pca.X_scores()[:,0], pca.X_scores()[:,1], bins=200)\n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 2\")\n",
    "labs = pollution.columns[4:].tolist()\n",
    "# Add an axis cross in gray using axhline and axvline\n",
    "plt.axhline(0, color=\"gray\")\n",
    "plt.axvline(0, color=\"gray\")\n",
    "# Add the loadings as text (labs) in white on top of the histogram, scale to the same range as the histogram\n",
    "for i in range(len(labs)):\n",
    "    plt.text(pca.X_loadings()[i,0]*4, pca.X_loadings()[i,1]*4, labs[i], color=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the 3rd and 4th components\n",
    "loadings(pca, comp=[3,4], XvarNames=pollution.columns[4:].tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resources\n",
    "- [Wikipedia: Fast Fourier Transform](https://en.wikipedia.org/wiki/Fast_Fourier_transform)\n",
    "- [Wikipedia: Discrete Cosine Transform](https://en.wikipedia.org/wiki/Discrete_cosine_transform)\n",
    "- [SciPy: Fourier Transforms](https://docs.scipy.org/doc/scipy/tutorial/fft.html)\n",
    "- [Seasonal-Trend decomposition using LOESS](https://www.statsmodels.org/stable/examples/notebooks/generated/stl_decomposition.html)\n",
    "- [YouTube: Veritasium - the history of FFT](https://youtu.be/nmgFG7PUHfo?si=fx2C0vuByBqorCAS) (26m:33s)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
