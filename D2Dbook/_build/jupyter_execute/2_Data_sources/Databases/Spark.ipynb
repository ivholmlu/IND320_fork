{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark\n",
    "- A fast and general compute engine (for [Hadoop](https://hadoop.apache.org/) data).\n",
    "    - Often paired with Hadoop for its distributed filesystem (HDFS), cluster resource management and parallel processing.\n",
    "- Spark provides a simple and expressive programming model that supports a wide range of applications, including ETL (extract, transform, load), Machine Learning, stream processing, and graph computation.\n",
    "- Also communicates well with some databases and other resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark and Cassandra\n",
    "- Cassandra is one of the databases that work well with Spark.\n",
    "    - Same type of distributed processing.\n",
    "    - Same way of replicating for fault tolerance.\n",
    "- Spark can be deployed on the same nodes as Cassandra for:\n",
    "    - local (short traveled) data manipulation, and\n",
    "    - combination of results to a central hub ([MapReduce](https://en.wikipedia.org/wiki/MapReduce)).\n",
    "- Requires drivers from Datastax\n",
    "    - Automatically downloaded and applied with the following configuration.\n",
    "- A [SparkSession](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.SparkSession.html) instantiates Spark, applies configurations and connects to a data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/kristian/miniforge3/envs/tf_M1/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/kristian/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/kristian/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-35370cd7-c95b-421a-807b-f29cf6ac2d95;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.4.1 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.1 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.13.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.13.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      ":: resolution report :: resolve 279ms :: artifacts dl 27ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.1 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.4.1 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   19  |   0   |   0   |   0   ||   19  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-35370cd7-c95b-421a-807b-f29cf6ac2d95\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 19 already retrieved (0kB/14ms)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/28 09:28:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/28 09:28:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sparkSession = SparkSession.builder.appName('SparkCassandraApp').\\\n",
    "    config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.4.1').\\\n",
    "    config('spark.cassandra.connection.host', 'localhost').\\\n",
    "    config('spark.sql.extensions', 'com.datastax.spark.connector.CassandraSparkExtensions').\\\n",
    "    config('spark.sql.catalog.mycatalog', 'com.datastax.spark.connector.datasource.CassandraCatalog').\\\n",
    "    config('spark.cassandra.connection.port', '9042').getOrCreate()\n",
    "# Some warnings are to be expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/28 09:28:52 WARN ControlConnection: [s0] Error connecting to Node(endPoint=localhost/127.0.0.1:9042, hostId=null, hashCode=50a8b790), trying next node (ConnectionInitException: [s0|control|id: 0xcf6fd472, L:/127.0.0.1:49207 - R:localhost/127.0.0.1:9042] Protocol initialization request, step 1 (OPTIONS): unexpected failure (java.lang.IllegalArgumentException: Unsupported request opcode: 0 in protocol 127))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+\n",
      "|ind| company|  model|\n",
      "+---+--------+-------+\n",
      "|  3|Polestar|      3|\n",
      "|  1|   Tesla|Model S|\n",
      "|  2|   Tesla|Model 3|\n",
      "+---+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# .load() is used to load data from Cassandra table as a Spark DataFrame.\n",
    "sparkSession.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"my_first_table\", keyspace=\"my_first_keyspace\").load().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database views\n",
    "- Useful for \"setting the scene\" before a more simplified data extraction.\n",
    "- The below example simply attaches to the correct keyspace and table.\n",
    "    - The _view_ could also be a selection into that table to query further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create view for simpler SQL queries\n",
    "sparkSession.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"my_first_table\", keyspace=\"my_first_keyspace\").load().createOrReplaceTempView(\"my_first_table_view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Spark DataFrame](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.html)\n",
    "- Related to a Pandas data frame, but can be distributed over compute nodes.\n",
    "- Various functions like filters, statistical calculations, groupBy, Pandas functions (mapInPandas), joins, etc.\n",
    "- Export to Pandas and JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+\n",
      "|ind|company|  model|\n",
      "+---+-------+-------+\n",
      "|  1|  Tesla|Model S|\n",
      "|  2|  Tesla|Model 3|\n",
      "+---+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select only Tesla company\n",
    "sparkSession.sql(\"select * from my_first_table_view\").filter(\"company = 'Tesla'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>company</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Model S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Model 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Polestar</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ind   company    model\n",
       "0    1     Tesla  Model S\n",
       "1    2     Tesla  Model 3\n",
       "2    3  Polestar        3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all data from the view and convert it to Pandas DataFrame\n",
    "sparkSession.sql(\"select * from my_first_table_view\").toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_M1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}